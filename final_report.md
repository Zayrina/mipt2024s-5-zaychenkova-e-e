**In progress**
* Собраны и размечены 87 изображений, содержащих баркоды.

* Индивидуальное задание — **Dewrapper баркодов**:
**Постановка задачи**: по изображению с искаженным баркодом восстанавливать изображение с распрямленным. 
По сути задача аналогична выпрямлению искаженного листа бумаги, поэтому рассмотрим более общую задачу выпрямления документов.
**Ключевые слова**: barcode/document/paper unwarping/dewarping/dewrapping.

**Анализ задачи**:
— Возможные типы искажений баркодов: смятие (без перекрытия и с перекрытием), загибы, отсутствие части баркода (она может быть оторвана, закрашена, закрыта другими объектами, загнута вниз); объект, на котором находится баркод, не является плоским (например, это цилиндрическая бутылка). Ситуации, когда баркод частично не виден, принципиально делятся на случаи, когда отсутствующую часть можно восстановить по видимой без потери смысла (например, если частично не видны полосы в одномерном баркоде, но для каждой полосы есть сохранившийся участок, который можно просто продолжить) и когда для восстановления баркода имеющегося контекста недостаточно.  

1. **Обзор литературы** 
 * Классические методы (без использования глубокого обучения). Базовые методы для выравнивания изображений документов могут подразумевать физическое подстраивание под задачу, например, использование одного или нескольких лазеров (https://scholarbank.nus.edu.sg/handle/10635/39819) или сопоставление нескольких изображений одной сцены, снятых с разных ракурсов (http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_CVPR_2007/data/papers/0283.pdf), для вычисления трехмерной формы документа (смятого листа бумаги). 
Опирающиеся на компьютерное зрение, но не использующие нейронные сети подходы чаще всего связаны с анализом теней на изображении (анализом того, как форма поверхности влияет на изменение направления пучков света: https://link.springer.com/article/10.1023/A:1007906904009, https://link.springer.com/article/10.1007/s00138-006-0062-y ), распознаванием и анализом искажений краев листов и строк текста (предполагается, что строки параллельны горизонтальным краям документа): https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=f8950709754ed50bd1432d6e86972b0665233d46 ). Однако такие подходы, как правило, позволяют исправлять только простые искажения, потому что опираются на предположение, что документ имеет цилиндрическую форму, или на наличие на документе текста (которого может там не быть) и разбиение этого текста на строки (что тоже является сильным ограничением применимости). Кроме того, для нахождения строк используются алгоритмы сегментации, которые с большой вероятностью будут неустойчивы к случаям с большими искажениями документов (когда лист мятый и сильно частично перекрывается). Помимо этого, такие классические подходы обычно направлены на исправление искажений определенного типа (например, загибов), поэтому для качественного выпрямления документа нужно использовать комбинацию разных классических методов.

  Среди современных подходов, опирающихся на глубокое обучение, интересными являются следующие работы:
  * https://openaccess.thecvf.com/content_cvpr_2018/html/Ma_DocUNet_Document_Image_CVPR_2018_paper.html (2018 год).
    
  * https://pdfs.semanticscholar.org/c372/c43c399e75e114099953b3549bd73f6d168f.pdf (2019). Предлагается метод, использующий pix2pixhd нейронную сеть, основанную на Conditional Generative Adversarial Network (CGAN). На входе и выходе — изображение документа. Обучение на синтетических данных, тестирование — и на синтетических, и на реальных. Для проверки качества работы алгоритма используются метрики, основанные на попиксельном сравнении исходного и восстановленного изображений: Pixel Accuracy, Mean Accuracy, Frequency Weighted IU, а также индекс структурного сходства SSIM и Haar Perceptual Similarity Index (HaarPSI), который отличается высокой скоррелированностью с MOS (восприятием человека).

  * https://arxiv.org/pdf/2104.06815 (2021).
Авторы учат полносвязную нейросетку на синтезированных данных, где изображения смятого документа сопровождаются разметкой в виде “потоков смещений” (displacement flow). Двухголовая сетка предсказывает для каждого пикселя изображения смятого документа смещение (регрессия) + является ли этот пиксель фоном (бинарная классификация). Авторы также предлагают метод регуляризации для контроля гладкости потока смещений, то есть того, что выровненный документ имеет непрерывную форму, и того, что выравнивание сохраняет локальные детали. Метод тестируется на реальных изображениях. В качестве метрики для оценки алгоритма используется Multi-Scale Structural Similarity (MS-SSIM) — индекс структурного сходства на разных масштабах изображений, а также Local Distortion (LD), который оценивает локальные признаки путем подсчета dense SIFT flow — плотного потока на основе нахождения особых точек.

  * https://arxiv.org/pdf/2203.10543 
Метод основан на нахождении и сопоставлении друг другу контрольных и референсных точек (первые находятся на исходном изображении документа, вторые — на его искаженном изображении и взаимно однозначно соответствуют первым). Нейронная сеть-энкодер используется для нахождения признаков, по которым затем и определяются контрольные и референсные точки. Затем с помощью интерполяционного подхода (TPS, Linear, Cubic или др.) находится попиксельное преобразование, которое переводит контрольные точки в референсные. Как и в предыдущей статье, для оценки качества алгоритма используются MS-SSIM и Local Distortion (LD).

Таким образом, обзор литературы показывает, что для решения этой задачи лучше всего подходят нейросетевые методы (они являются более универсальными).




